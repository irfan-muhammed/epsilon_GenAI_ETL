# ğŸ¤– GenAI-Powered ETL Agent

An intelligent ETL (Extract-Transform-Load) pipeline orchestrated by a GenAI agent using **LangGraph** and **Azure OpenAI**.

## ğŸ¯ Overview

This project demonstrates how Large Language Models (LLMs) can be used to create intelligent, self-correcting ETL pipelines. Instead of hardcoded transformation rules, the agent **reasons** about data, **plans** transformations dynamically, and **adapts** to changes automatically.

### Key Features

- **ğŸ§  Intelligent Schema Analysis**: LLM understands data structure and identifies quality issues
- **ğŸ“‹ Dynamic Transformation Planning**: Agent generates transformation steps based on data characteristics
- **ğŸ”„ Self-Correcting Pipeline**: Automatic error recovery with LLM-guided re-planning
- **ğŸ¯ Schema Adaptation**: Handles schema changes without code modifications
- **âœ… Validation Generation**: LLM creates appropriate validation rules

---

## ğŸ—ï¸ Architecture

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    GENAI ETL AGENT ARCHITECTURE                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                          â•‘
â•‘    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘    â”‚                    LangGraph State Machine                       â”‚   â•‘
â•‘    â”‚                                                                  â”‚   â•‘
â•‘    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â•‘
â•‘    â”‚   â”‚ EXTRACT  â”‚â”€â”€â”€â–¶â”‚ ANALYZE  â”‚â”€â”€â”€â–¶â”‚   PLAN   â”‚â”€â”€â”€â–¶â”‚TRANSFORM â”‚  â”‚   â•‘
â•‘    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â•‘
â•‘    â”‚        â”‚               â”‚               â”‚               â”‚        â”‚   â•‘
â•‘    â”‚        â–¼               â–¼               â–¼               â–¼        â”‚   â•‘
â•‘    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â•‘
â•‘    â”‚   â”‚   Tool   â”‚    â”‚   LLM    â”‚    â”‚   LLM    â”‚    â”‚   Tool   â”‚  â”‚   â•‘
â•‘    â”‚   â”‚ extract  â”‚    â”‚ analyze  â”‚    â”‚  plan    â”‚    â”‚transform â”‚  â”‚   â•‘
â•‘    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â•‘
â•‘    â”‚                                                                  â•‘
â•‘    â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚   â•‘
â•‘    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   ERROR HANDLER   â”‚                    â”‚   â•‘
â•‘    â”‚   â”‚ VALIDATE â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   (LLM Recovery)  â”‚â—€â”€â”€â”€â”€â”€â”€ on error    â”‚   â•‘
â•‘    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚   â•‘
â•‘    â”‚        â”‚                        â”‚                               â”‚   â•‘
â•‘    â”‚        â–¼                        â”‚ retry                         â”‚   â•‘
â•‘    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                               â”‚   â•‘
â•‘    â”‚   â”‚   LOAD   â”‚â”€â”€â”€â–¶â”‚  VERIFY  â”‚â”€â”€â”´â”€â”€â–¶ END                        â”‚   â•‘
â•‘    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚   â•‘
â•‘    â”‚                                                                  â”‚   â•‘
â•‘    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                          â•‘
â•‘    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘    â”‚                    Azure OpenAI (LLM)                            â”‚   â•‘
â•‘    â”‚  â€¢ Schema analysis & understanding                               â”‚   â•‘
â•‘    â”‚  â€¢ Transformation planning                                       â”‚   â•‘
â•‘    â”‚  â€¢ Validation rule generation                                    â”‚   â•‘
â•‘    â”‚  â€¢ Error recovery & re-planning                                  â”‚   â•‘
â•‘    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•‘                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸš€ How the Agent Reasons and Plans

### Step 1: Extract & Analyze

The agent extracts data and performs deep schema analysis:

```python
# Agent automatically detects:
- Column types (numeric, datetime, categorical)
- Null values and their percentages  
- Outliers and invalid values
- Potential type mismatches
```

### Step 2: LLM-Powered Planning

The LLM receives the schema analysis and generates a transformation plan:

```
INPUT (to LLM):
- Schema summary with 18 columns
- Data quality issues: negative passenger counts, invalid rate codes
- User instructions: "Clean data for analysis"

OUTPUT (from LLM):
[
    {"action": "convert_datetime", "column": "pickup_datetime"},
    {"action": "fill_null", "column": "passenger_count", "strategy": "median"},
    {"action": "remove_negative", "column": "passenger_count"},
    {"action": "remove_invalid", "column": "RatecodeID", "valid_values": [1,2,3,4,5,6]}
]
```

### Step 3: Execute & Validate

The agent executes transformations and generates validation rules:

```
Transformation Log:
âœ… Step 1: convert_datetime on 'pickup_datetime' - Success
âœ… Step 2: fill_null on 'passenger_count' - Filled 1 null values
âœ… Step 3: remove_negative on 'passenger_count' - Removed 1 rows

Validation:
âœ… passenger_count should not have nulls - Passed
âœ… fare_amount should be positive - Passed
âœ… Should have at least 10 rows - Passed (23 rows)
```

### Step 4: Error Recovery (Self-Healing)

If something fails, the LLM suggests a recovery plan:

```
ERROR: Column 'RatecodeID' contains non-numeric value 'INVALID'

LLM RECOVERY:
"The RatecodeID column has mixed types. Adding type conversion before validation."

NEW PLAN:
[
    {"action": "convert_numeric", "column": "RatecodeID"},
    {"action": "fill_null", "column": "RatecodeID", "strategy": "mode"}
]
```

---

## ğŸ“ Project Structure

```
genai_etl_agent/
â”œâ”€â”€ .env.example              # Environment variables template
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # This file
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nyc_taxi_sample.csv       # Sample NYC taxi data
â”‚   â””â”€â”€ nyc_taxi_new_schema.csv   # Schema-changed version (for bonus demo)
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ (generated SQLite databases)
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ llm_setup.py          # Azure OpenAI configuration
    â”œâ”€â”€ main.py               # Entry point with demos
    â”‚
    â”œâ”€â”€ agent/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ etl_agent.py      # LangGraph agent implementation
    â”‚
    â””â”€â”€ tools/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ extract_tool.py   # Data extraction & schema analysis
        â”œâ”€â”€ transform_tool.py # Transformation execution
        â””â”€â”€ load_tool.py      # Database loading
```

---

## ğŸ› ï¸ Setup & Installation

### 1. Clone and Setup

```bash
cd genai_etl_agent
pip install -r requirements.txt
```

### 2. Configure Azure OpenAI

Create a `.env` file with your credentials:

```env
OPENAI_API_KEY=your_api_key_here
OPENAI_DEPLOYMENT_ENDPOINT=https://your-resource.openai.azure.com/
OPENAI_DEPLOYMENT_NAME=your_deployment_name
OPENAI_DEPLOYMENT_VERSION=2024-02-15-preview
OPENAI_MODEL_NAME=gpt-4
```

### 3. Run the Demo

```bash
cd src
python main.py
```

---

## ğŸ® Demo Scenarios

### Demo 1: Basic ETL Pipeline

Demonstrates the complete ETL flow with NYC taxi data:
- Schema analysis with quality issue detection
- LLM-generated transformation plan
- Automatic validation
- SQLite database loading

### Demo 2: Schema Change Adaptation (Bonus)

Shows how the agent handles a completely different schema:
- Original: `VendorID, tpep_pickup_datetime, passenger_count, ...`
- New: `vendor_id, pickup_time, num_passengers, ...`

The agent automatically adapts without code changes!

---

## ğŸ”§ Trade-offs and Limitations

### Trade-offs Made

| Decision | Trade-off |
|----------|-----------|
| **SQLite** | Simple PoC vs production scalability |
| **Small dataset** | Fast iteration vs large-scale testing |
| **Predefined transforms** | Safety vs flexibility |
| **JSON transformation plans** | Structured output vs natural language |

### Current Limitations

1. **Scale**: Designed for small-scale PoC data
2. **Transform Safety**: Only predefined transformations are allowed (prevents arbitrary code execution)
3. **Error Recovery**: Limited to 2 retries
4. **LLM Latency**: Each planning step requires an LLM call

### Production Considerations

For production use, consider:
- Connection pooling for databases
- Async execution for large datasets
- Caching of common transformation plans
- More robust error handling and logging
- Data lineage tracking

---

## ğŸ Bonus: Adaptation Scenarios

### If Schema Changes

The agent handles schema changes automatically:

1. **Detection**: Schema analyzer identifies new/renamed columns
2. **Adaptation**: LLM plans transformations based on semantic understanding
3. **Mapping**: Agent can map `passenger_count` â†’ `num_passengers`

### If Data Quality Degrades

The agent responds to quality degradation:

1. **Detection**: More quality issues flagged in analysis
2. **Planning**: LLM generates additional cleaning steps
3. **Validation**: Stricter rules generated for problematic columns

### If New Data Source Added

The agent adapts to new sources:

1. **Extraction**: Tool detects file type (CSV, JSON, Parquet)
2. **Analysis**: Schema analyzer works with any tabular data
3. **Planning**: LLM understands domain regardless of source

---

## ğŸ“Š What Makes This Stand Out

1. **True Reasoning**: The agent doesn't just execute rulesâ€”it *thinks* about data
2. **Self-Healing**: Automatic error recovery with LLM guidance
3. **Natural Language Interface**: Describe transformations in plain English
4. **Minimal Configuration**: No hardcoded rules for data types or transformations
5. **Observable**: Full reasoning log shows agent's decision process

---

## ğŸ§ª Testing the Agent

```python
from agent.etl_agent import create_etl_agent

# Create agent
agent = create_etl_agent()

# Run pipeline with natural language instructions
result = agent.run(
    source_path="./data/nyc_taxi_sample.csv",
    target_db="./output/my_data.db",
    target_table="trips",
    user_instructions="Clean the data, handle missing values, remove outliers"
)

# Check results
print(f"Status: {result['final_status']}")
print(f"Rows loaded: {result['load_result']['rows_loaded']}")
```

---

## ğŸ“š Technologies Used

- **LangGraph**: State machine orchestration for agent workflow
- **LangChain**: LLM integration and tooling
- **Azure OpenAI**: GPT-4 for reasoning and planning
- **Pandas**: Data manipulation
- **SQLite**: Target database

---

## ğŸ“„ License

MIT License - Feel free to use and modify for your own projects.
